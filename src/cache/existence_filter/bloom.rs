use async_trait::async_trait;
use bloomfilter::Bloom;
use futures_util::StreamExt;
use parking_lot::{Mutex, RwLock};
use std::pin::Pin;
use std::sync::Arc;
use tracing::debug;

use crate::cache::ExistenceFilter;
use crate::declare_existence_filter_plugin;
use crate::errors::{Result, ShortlinkerError};
use futures_util::stream::Stream;

declare_existence_filter_plugin!("bloom", BloomExistenceFilterPlugin);

pub struct BloomExistenceFilterPlugin {
    inner: Arc<RwLock<Bloom<str>>>,
    /// rebuild æœŸé—´æ”¶é›†æ–°å¢ key çš„ bufferã€‚
    /// Some = æ­£åœ¨é‡å»ºï¼Œset() ä¼šåŒæ—¶å†™å…¥ buffer
    /// None = æœªåœ¨é‡å»º
    rebuild_buffer: Mutex<Option<Vec<String>>>,
}

impl Default for BloomExistenceFilterPlugin {
    fn default() -> Self {
        Self::new().expect("Failed to create default BloomExistenceFilterPlugin")
    }
}

impl BloomExistenceFilterPlugin {
    pub fn new() -> Result<Self> {
        // ä½¿ç”¨æœ€å°åˆå§‹å®¹é‡ï¼Œå› ä¸º startup.rs ä¸­çš„ rebuild_all() ä¼šç«‹å³ç”¨å®é™…æ•°é‡æ›¿æ¢
        let bloom = Bloom::new_for_fp_rate(100, 0.001).map_err(|e| {
            ShortlinkerError::cache_connection(format!("Failed to create bloom filter: {e}"))
        })?;
        Ok(Self {
            inner: Arc::new(RwLock::new(bloom)),
            rebuild_buffer: Mutex::new(None),
        })
    }
}

/// åˆ†æ®µé¢„ç•™ç­–ç•¥ï¼Œè®¡ç®— Bloom Filter å®é™…å®¹é‡
/// - < 5000: é¢„ç•™ 50%ï¼ˆå°è§„æ¨¡éœ€è¦æ›´å¤šä½™é‡ï¼‰
/// - 5000-100000: é¢„ç•™ 20%
/// - > 100000: é¢„ç•™ 10%ï¼ˆæœ€å¤š 100 ä¸‡ï¼‰
fn calculate_capacity(count: usize) -> usize {
    let reserve = if count < 5000 {
        count / 2
    } else if count < 100000 {
        count / 5
    } else {
        (count / 10).min(1_000_000)
    };
    count + reserve.max(1000) // æœ€å°‘é¢„ç•™ 1000
}

#[async_trait]
impl ExistenceFilter for BloomExistenceFilterPlugin {
    async fn check(&self, key: &str) -> bool {
        let bloom = self.inner.read();
        bloom.check(key)
    }

    async fn set(&self, key: &str) {
        // é”é¡ºåºï¼šbuffer lock â†’ inner write lockï¼ˆä¸ rebuild_streaming ä¸€è‡´ï¼Œé˜²æ­¢æ­»é”ï¼‰
        let mut buffer_guard = self.rebuild_buffer.lock();
        self.inner.write().set(key);
        if let Some(ref mut buffer) = *buffer_guard {
            buffer.push(key.to_string());
        }
    }

    async fn bulk_set(&self, keys: &[String]) {
        let mut bloom = self.inner.write();
        for key in keys {
            bloom.set(key);
        }
        debug!("Bulk inserted {} keys into bloom filter", keys.len());
    }

    async fn clear(&self, count: usize, fp_rate: f64) -> Result<()> {
        let mut bloom = self.inner.write();
        let capacity = calculate_capacity(count);
        *bloom = Bloom::new_for_fp_rate(capacity, fp_rate).map_err(|e| {
            ShortlinkerError::cache_connection(format!("Failed to clear bloom filter: {e}"))
        })?;
        debug!(
            "Bloom filter cleared with capacity: {} (count: {} + reserve: {}), fp_rate: {}",
            capacity,
            count,
            capacity - count,
            fp_rate
        );
        Ok(())
    }

    /// åœ¨é”å¤–æ„å»ºå®Œæ•´çš„æ–° Bloom Filterï¼Œç„¶ååŸå­äº¤æ¢ã€‚
    /// è¯»å–ç«¯çœ‹åˆ°çš„è¦ä¹ˆæ˜¯æ—§çš„å®Œæ•´ Bloomï¼Œè¦ä¹ˆæ˜¯æ–°çš„å®Œæ•´ Bloomï¼Œæ°¸è¿œä¸ä¼šçœ‹åˆ°ç©º Bloomã€‚
    /// rebuild æœŸé—´é€šè¿‡ buffer æ•è·å¹¶å‘ set() å†™å…¥çš„ keyï¼Œç¡®ä¿é›¶ä¸¢å¤±ã€‚
    async fn rebuild(&self, keys: &[String], count: usize, fp_rate: f64) -> Result<()> {
        // å¯ç”¨ bufferï¼Œæ•è· rebuild æœŸé—´çš„å¹¶å‘å†™å…¥
        *self.rebuild_buffer.lock() = Some(Vec::new());

        let capacity = calculate_capacity(count);
        let mut new_bloom = Bloom::new_for_fp_rate(capacity, fp_rate).map_err(|e| {
            // æ„å»ºå¤±è´¥æ—¶å…³é—­ buffer
            *self.rebuild_buffer.lock() = None;
            ShortlinkerError::cache_connection(format!("Failed to rebuild bloom filter: {e}"))
        })?;
        for key in keys {
            new_bloom.set(key.as_str());
        }

        // æŒ buffer lock â†’ drain buffer â†’ äº¤æ¢ â†’ å…³é—­ buffer
        let buffered_count;
        {
            let mut buffer_guard = self.rebuild_buffer.lock();
            if let Some(ref pending) = *buffer_guard {
                buffered_count = pending.len();
                for key in pending {
                    new_bloom.set(key.as_str());
                }
            } else {
                buffered_count = 0;
            }
            *self.inner.write() = new_bloom;
            *buffer_guard = None;
        }

        debug!(
            "Bloom filter rebuilt atomically with {} keys ({} from buffer), capacity: {} (count: {} + reserve: {}), fp_rate: {}",
            keys.len() + buffered_count,
            buffered_count,
            capacity,
            count,
            capacity - count,
            fp_rate
        );
        Ok(())
    }

    /// æµå¼é‡å»º Bloom Filterï¼šç”¨ count é¢„åˆ†é…ï¼Œä» Stream é€æ‰¹åŠ è½½ï¼Œæœ€ååŸå­äº¤æ¢ã€‚
    /// å†…å­˜å ç”¨ O(batch_size) è€Œé O(total_keys)ï¼Œé¿å…å¤§æ•°æ®é‡ OOMã€‚
    /// rebuild æœŸé—´é€šè¿‡ buffer æ•è·å¹¶å‘ set() å†™å…¥çš„ keyï¼Œç¡®ä¿é›¶ä¸¢å¤±ã€‚
    async fn rebuild_streaming(
        &self,
        count: usize,
        fp_rate: f64,
        stream: Pin<Box<dyn Stream<Item = Result<Vec<String>>> + Send>>,
    ) -> Result<()> {
        // å¯ç”¨ bufferï¼Œæ•è· rebuild æœŸé—´çš„å¹¶å‘å†™å…¥
        *self.rebuild_buffer.lock() = Some(Vec::new());

        let capacity = calculate_capacity(count);
        let mut new_bloom = Bloom::new_for_fp_rate(capacity, fp_rate).map_err(|e| {
            *self.rebuild_buffer.lock() = None;
            ShortlinkerError::cache_connection(format!(
                "Failed to create bloom filter for streaming rebuild: {e}"
            ))
        })?;

        let mut loaded: usize = 0;
        let mut stream = stream;

        while let Some(batch_result) = stream.next().await {
            match batch_result {
                Ok(batch) => {
                    for key in &batch {
                        new_bloom.set(key.as_str());
                    }
                    loaded += batch.len();
                }
                Err(e) => {
                    // æµå¼è¯»å–å¤±è´¥ï¼Œå…³é—­ bufferï¼Œæ—§ Bloom ä¿æŒä¸å˜
                    *self.rebuild_buffer.lock() = None;
                    return Err(e);
                }
            }
        }

        // æŒ buffer lock â†’ drain buffer â†’ äº¤æ¢ â†’ å…³é—­ buffer
        let buffered_count;
        {
            let mut buffer_guard = self.rebuild_buffer.lock();
            if let Some(ref pending) = *buffer_guard {
                buffered_count = pending.len();
                for key in pending {
                    new_bloom.set(key.as_str());
                }
            } else {
                buffered_count = 0;
            }
            *self.inner.write() = new_bloom;
            *buffer_guard = None;
        }

        debug!(
            "Bloom filter rebuilt (streaming) with {} keys ({} from buffer), capacity: {} (count: {} + reserve: {}), fp_rate: {}",
            loaded + buffered_count,
            buffered_count,
            capacity,
            count,
            capacity - count,
            fp_rate
        );
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_check_empty_returns_false() {
        let filter = BloomExistenceFilterPlugin::new().unwrap();
        assert!(!filter.check("nonexistent").await);
    }

    #[tokio::test]
    async fn test_set_and_check() {
        let filter = BloomExistenceFilterPlugin::new().unwrap();

        filter.set("test_key").await;
        assert!(filter.check("test_key").await);

        // æœªè®¾ç½®çš„ key åº”è¯¥è¿”å› falseï¼ˆå¤§æ¦‚ç‡ï¼‰
        assert!(!filter.check("other_key").await);
    }

    #[tokio::test]
    async fn test_bulk_set() {
        let filter = BloomExistenceFilterPlugin::new().unwrap();
        let keys: Vec<String> = (0..100).map(|i| format!("key_{}", i)).collect();

        filter.bulk_set(&keys).await;

        // æ‰€æœ‰è®¾ç½®çš„ key éƒ½åº”è¯¥å­˜åœ¨
        for key in &keys {
            assert!(filter.check(key).await, "Key {} should exist", key);
        }
    }

    #[tokio::test]
    async fn test_clear_resets_filter() {
        let filter = BloomExistenceFilterPlugin::new().unwrap();

        filter.set("test_key").await;
        assert!(filter.check("test_key").await);

        filter.clear(1000, 0.001).await.unwrap();

        // æ¸…é™¤åï¼Œä¹‹å‰çš„ key åº”è¯¥ä¸å­˜åœ¨äº†
        assert!(!filter.check("test_key").await);
    }

    #[tokio::test]
    async fn test_rebuild_replaces_filter_atomically() {
        let filter = BloomExistenceFilterPlugin::new().unwrap();

        // å…ˆæ’å…¥ä¸€äº›æ—§ key
        filter.set("old_key_1").await;
        filter.set("old_key_2").await;
        assert!(filter.check("old_key_1").await);

        // ç”¨æ–° key åˆ—è¡¨ rebuild
        let new_keys = vec!["new_key_a".to_string(), "new_key_b".to_string()];
        filter
            .rebuild(&new_keys, new_keys.len(), 0.001)
            .await
            .unwrap();

        // æ—§ key åº”è¯¥ä¸å­˜åœ¨äº†
        assert!(!filter.check("old_key_1").await);
        assert!(!filter.check("old_key_2").await);

        // æ–° key åº”è¯¥å­˜åœ¨
        assert!(filter.check("new_key_a").await);
        assert!(filter.check("new_key_b").await);
    }

    #[tokio::test]
    async fn test_unicode_key() {
        let filter = BloomExistenceFilterPlugin::new().unwrap();

        filter.set("ä¸­æ–‡é”®").await;
        assert!(filter.check("ä¸­æ–‡é”®").await);

        filter.set("ğŸ‰emoji").await;
        assert!(filter.check("ğŸ‰emoji").await);
    }

    #[tokio::test]
    async fn test_false_positive_rate_within_bounds() {
        let filter = BloomExistenceFilterPlugin::new().unwrap();

        // é‡æ–°é…ç½®ä¸ºè¶³å¤Ÿå¤§çš„å®¹é‡ï¼ˆåˆå§‹å®¹é‡åªæœ‰ 100ï¼‰
        filter.clear(1000, 0.001).await.unwrap();

        // æ’å…¥ 1000 ä¸ª key
        let keys: Vec<String> = (0..1000).map(|i| format!("existing_{}", i)).collect();
        filter.bulk_set(&keys).await;

        // æµ‹è¯• 10000 ä¸ªä¸å­˜åœ¨çš„ keyï¼Œç»Ÿè®¡è¯¯æŠ¥ç‡
        let mut false_positives = 0;
        for i in 0..10000 {
            if filter.check(&format!("nonexistent_{}", i)).await {
                false_positives += 1;
            }
        }

        // é»˜è®¤ fp_rate æ˜¯ 0.001ï¼Œå…è®¸ä¸€å®šè¯¯å·®
        // 10000 æ¬¡æŸ¥è¯¢ï¼ŒæœŸæœ›è¯¯æŠ¥çº¦ 10 æ¬¡ï¼Œå…è®¸æœ€å¤š 50 æ¬¡ï¼ˆ0.5%ï¼‰
        assert!(
            false_positives < 50,
            "False positive rate too high: {}/10000",
            false_positives
        );
    }

    #[tokio::test]
    async fn test_concurrent_set_and_check() {
        use std::sync::Arc;

        let filter = Arc::new(BloomExistenceFilterPlugin::new().unwrap());
        let mut handles = vec![];

        // å¹¶å‘è®¾ç½® 100 ä¸ª key
        for i in 0..100 {
            let f = Arc::clone(&filter);
            handles.push(tokio::spawn(async move {
                f.set(&format!("concurrent_key_{}", i)).await;
            }));
        }

        for handle in handles {
            handle.await.unwrap();
        }

        // éªŒè¯æ‰€æœ‰ key éƒ½å­˜åœ¨
        for i in 0..100 {
            assert!(
                filter.check(&format!("concurrent_key_{}", i)).await,
                "Key {} should exist after concurrent set",
                i
            );
        }
    }
}
